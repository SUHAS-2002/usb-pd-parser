# src/extractors/chunk_extractor.py

import re
from typing import List, Dict


class ChunkExtractor:
    """
    Robust chunk extractor for USB-PD Specification.

    Fixes implemented:
    - Ensures 100% page coverage
    - Detects only true section headings (ignores tables/figures)
    - Uses TOC + internal headings for precise segmentation
    - Prevents overlapping or empty chunks
    - Adds fallback unmapped pages
    """

    # Start-of-line strict heading (NOT inside sentences/tables)
    SECTION_RE = re.compile(
        r"^(?:\s*)(\d+(?:\.\d+)+)\s+[A-Za-z]",
        re.MULTILINE,
    )

    # ------------------------------------------------------------------
    def extract(self, pages: List[Dict], toc: List[Dict]) -> List[Dict]:
        """
        Build section chunks using TOC + internal heading detection.
        """
        if not pages:
            return []

        page_numbers = [p["page_number"] for p in pages]
        min_page = min(page_numbers)
        max_page = max(page_numbers)

        page_text: Dict[int, str] = {}

        for pg in pages:
            num = pg["page_number"]
            text = pg.get("text") or ""
            page_text[num] = text

        # Fill missing pages
        for p in range(min_page, max_page + 1):
            page_text.setdefault(p, "")

        # Internal headings
        internal_starts = self._find_true_internal_headings(page_text)

        # Sort TOC entries
        toc_sorted = sorted(
            toc,
            key=lambda e: (e["page"], self._key(e["section_id"])),
        )

        section_start_override: Dict[str, int] = {}
        for sid, pg in internal_starts.items():
            section_start_override[sid] = pg

        chunks: List[Dict] = []
        mapped = set()

        # --------------------------------------------------------------
        # Build chunks using TOC ordering
        # --------------------------------------------------------------
        for idx, entry in enumerate(toc_sorted):
            sid = entry["section_id"]

            start = section_start_override.get(sid, entry["page"])

            if idx + 1 < len(toc_sorted):
                next_sid = toc_sorted[idx + 1]["section_id"]
                next_start = section_start_override.get(
                    next_sid,
                    toc_sorted[idx + 1]["page"],
                )
                end = next_start - 1
            else:
                end = max_page

            # Clamp
            start = max(start, min_page)
            end = min(end, max_page)
            if end < start:
                end = start

            # Extract combined text
            combined = []
            for p in range(start, end + 1):
                combined.append(page_text.get(p, ""))

            content = "\n\n".join(combined).strip()

            for p in range(start, end + 1):
                mapped.add(p)

            chunks.append(
                {
                    "doc_title": entry["doc_title"],
                    "section_id": sid,
                    "title": entry["title"],
                    "full_path": entry["full_path"],
                    "page_range": [start, end],
                    "content": content,
                    "tags": entry.get("tags", []),
                }
            )

        # --------------------------------------------------------------
        # Add unmapped pages
        # --------------------------------------------------------------
        for p in range(min_page, max_page + 1):
            if p not in mapped:
                chunks.append(
                    {
                        "doc_title": "USB Power Delivery Specification",
                        "section_id": f"unmapped-{p}",
                        "title": f"Unmapped Page {p}",
                        "full_path": f"Unmapped Page {p}",
                        "page_range": [p, p],
                        "content": page_text.get(p, ""),
                        "tags": [],
                    }
                )

        chunks.sort(key=lambda c: c["page_range"][0])
        return chunks

    # ------------------------------------------------------------------
    # Internal Helpers
    # ------------------------------------------------------------------
    def _find_true_internal_headings(
        self, page_text: Dict[int, str]
    ) -> Dict[str, int]:
        """
        Detect true section headings inside page content.
        Filters out table IDs, figure numbers, etc.
        """
        found: Dict[str, int] = {}

        for page_num, text in page_text.items():
            for match in self.SECTION_RE.finditer(text):
                sid = match.group(1)
                if self._plausible(sid):
                    found.setdefault(sid, page_num)

        return found

    @staticmethod
    def _key(section_id: str) -> tuple:
        """Convert '7.2.10' â†’ (7, 2, 10)."""
        return tuple(int(x) for x in section_id.split("."))

    @staticmethod
    def _plausible(sid: str) -> bool:
        """Reject unrealistic or garbage section IDs."""
        try:
            top = int(sid.split(".")[0])
        except ValueError:
            return False

        return 1 <= top <= 20
